{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#-----------------------------------------------------------------------------------------------------#\n",
      "#--------------Model Analysis and Testing With UsedAutoRELEVANTfirst10000-noLatLong.csv---------------#\n",
      "#---------------------------------For Customer Type / Person Type-------------------------------------#\n",
      "     Accuracy AVG Diviation\n",
      "LR : 0.836640 (0.015516)\n",
      "LDA: 0.925948 (0.011077)\n",
      "KNC: 0.821152 (0.015990)\n",
      "DTC: 0.988143 (0.006253)\n",
      "GNB: 0.818007 (0.015812)\n",
      "The best model results in a Decision Tree Model.\n",
      "\n",
      "Numeric to Person Type Key: \n",
      "2.0  >> P\n",
      "1.0  >> E\n",
      "0.0  >> Y\n",
      "3.0  >> O\n",
      "\n",
      "Sample Predictions: \n",
      "[2. 2. 2. ... 2. 2. 3.]\n",
      "\n",
      "Sample Actual:\n",
      "[2. 2. 2. ... 2. 2. 3.]\n",
      "\n",
      "Sample Accuracy:\n",
      "0.9738878143133463\n",
      "\n",
      "Sample Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        17\n",
      "         1.0       0.64      0.59      0.62        27\n",
      "         2.0       1.00      0.99      1.00       853\n",
      "         3.0       0.89      0.92      0.90       137\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.88      0.88      0.88      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Name: CS 458 Task 1 Testing File Predictions and Model Analysis\n",
    "#Authors: Liliana Pacheco, Chantelle Suarez, Yan Tarpley\n",
    "#Name: CS 458 Task 3 Person Type\n",
    "#Authors: Liliana Pacheco, Chantelle Suarez, Yan Tarpley\n",
    "#Date: December 9, 2019\n",
    "#Description: This code takes in the UsedAutoRELEVATEFfirst10000-noLatLong.csv excel sheet and then processes the data\n",
    "#by doing the follwoing thins:\n",
    "#   Removing empty columns and rows\n",
    "#   converting all non numeric data\n",
    "#   filling in missing values with the average for the columns\n",
    "#   removing columns with data that has more than 60% missing values\n",
    "#This code then goes on to analyse the data set for the best model and then making predictions for \n",
    "#the data set. The data set is splitt to 80% percent training to 20% testing and predictions or done for a target of\n",
    "#Person Type. Vehicle Type was analysed and evaluated on a different Code for readibility.\n",
    "#NOTE: The model analysis portion of this program was created using Jason Brownlee's article \n",
    "#\"How To Compare Machine Learning Algorithms in Python with scikit-learn\" as a referrence\n",
    "#Link to the article: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "#                                 May Change File Paths Here                                   #\n",
    "\n",
    "personDF = pd.read_excel(r\"C:\\Users\\lilia_fdv6j62\\Documents\\autoData.xlsx\", header=0)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#*    This Function was written using the following referrence\n",
    "#*    Title: Handling Non-Numerical Data for Machine Learning\n",
    "#*    Author: Harrison@pythonprogramming.net\n",
    "#*    Date: December 9, 2019\n",
    "#*    Availability: https://pythonprogramming.net/working-with-non-numerical-data-machine-learning-tutorial/\n",
    "#*\n",
    "#---------------------------------------------------------------------------------------\n",
    "def convertLabels(df):\n",
    "    columns = df.columns.values\n",
    "    for column in columns:\n",
    "        textValues = {}\n",
    "        def convert(val):\n",
    "            return textValues[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            contents = df[column].values.tolist()\n",
    "            uniqueVal = set(contents)\n",
    "            x = 0\n",
    "            for unique in uniqueVal:\n",
    "                if unique not in textValues:\n",
    "                    textValues[unique] = x\n",
    "                    x+=1\n",
    "            df[column] = list(map(convert, df[column])) \n",
    "                \n",
    "    return df\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "#remove all empty columns in the dataframe\n",
    "personDF = personDF.dropna(axis = 1, how = 'all')\n",
    "\n",
    "#Move Target column \"Person Type\" to the end/right most column\n",
    "personDF = personDF[personDF['Person Type'].notnull()]\n",
    "personDFTarget = personDF.pop('Person Type')\n",
    "personDF['Person Type'] = personDFTarget\n",
    "\n",
    "#remove columns with more than 60% of data missing\n",
    "personDF = personDF.loc[:, personDF.isin([' ','NULL',0]).mean() < .4]\n",
    "#fill in any missing values with the average\n",
    "personDF.fillna(personDF.mean(), inplace = True)\n",
    "#Make All Data Numeric\n",
    "personDf = convertLabels(personDF)\n",
    "\n",
    "#Split Training Data For Model Analysis\n",
    "finalData = personDF.values\n",
    "xVal = finalData[:,0:len(personDF.columns) - 1]\n",
    "yVal= finalData[:,len(personDF.columns) - 1]\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(xVal, yVal, test_size=0.20, random_state=1)\n",
    "#Select Models For Testing\n",
    "models = []\n",
    "models.append(('LR ', LogisticRegression(solver='liblinear',multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNC', KNeighborsClassifier()))\n",
    "models.append(('DTC', DecisionTreeClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "\n",
    "#Evaluate Each Model\n",
    "print(\"\\n\\n#-----------------------------------------------------------------------------------------------------#\")\n",
    "print(\"#--------------Model Analysis and Testing With UsedAutoRELEVANTfirst10000-noLatLong.csv---------------#\")\n",
    "print(\"#---------------------------------For Customer Type / Person Type-------------------------------------#\")\n",
    "print(\"     Accuracy AVG Diviation\")\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=0)\n",
    "    cv_results = model_selection.cross_val_score(model, xTrain, yTrain, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "#Select The Best Model For Testing\n",
    "print(\"The best model results in a Decision Tree Model.\")\n",
    "testModel =  DecisionTreeClassifier()\n",
    "testModel.fit(xTrain, yTrain)\n",
    "\n",
    "#Make Sample Predictions\n",
    "testPredictions = testModel.predict(xTest)\n",
    "print(\"\\nNumeric to Person Type Key: \")\n",
    "print (personDF.iloc[0]['Person Type'], \" >> P\")\n",
    "print (personDF.iloc[1]['Person Type'], \" >> E\")\n",
    "print (personDF.iloc[7]['Person Type'], \" >> Y\")\n",
    "print (personDF.iloc[11]['Person Type'], \" >> O\")\n",
    "\n",
    "print(\"\\nSample Predictions: \")\n",
    "print(testPredictions)\n",
    "print(\"\\nSample Actual:\")\n",
    "print(yTest)\n",
    "\n",
    "# Evaluate Sample predictions\n",
    "print(\"\\nSample Accuracy:\")\n",
    "print(accuracy_score(yTest, testPredictions))\n",
    "\n",
    "print(\"\\nSample Report\")\n",
    "print(classification_report(yTest, testPredictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
